-------------해시테이블-------------

배열이나 연결리스트와는 달리 순서관계가 없다. key-value 데이터로, 파이썬의 딕셔너리를 생각하면 쉽다. 딕셔너리는 키로 호출하지 인덱스로 가져올 수 없는 것처럼. 그리고 하나의 key에는 무조건 하나의 value만 할당되어야함

direct access table
-key를 인덱스로 생각하고 저장하는 방법. 예시로 104호 지우, 1107호 지희, 207호 광호 이렇게 데이터가 있다면 가장 큰 key인 1107을 기준으로 배열 메모리를 확보한다. 그리고 104주소에 지우를 넣고 207주소 칸에 광호를 넣는다. 이렇게 하면 배열의 접근연산을 사용해서 O(1)에 접근할 수 있다. 근데 문제는 낭비되는 공간이 너무 많다는 것. 1107개의 칸을 확보했는데 그 중에 3개만 사용하고 있고 나머지는 그냥 버려지는 공간이 되어버린다. 또한 key가 순서를 따질 수 없는 데이터유형이면 불가능할듯? 어쨌든 이런식으로 배열인덱스를 key로 이용해서 저장하는 방식을 direct access table이라고 한다.

hash table
-direct access table은 시간은 효율적이지만 공간이 비효율적이다. 해시테이블은 그에 비해 시간과 공간 둘 다 효율적으로 사용할 수 있는 방식이다. 우선 이 방식은 해시함수를 사용하는데 해시함수는 임의의 길이를 갖는 데이터에 대해 고정된 길이의 데이터로 변환해준다. 즉 1, 32, 10007, 230659000 를 넣어도 내가 1-100범위로 설정했으면 해시함수를 통해 2, 45, 71, 12 이런식으로 나온다는거. 이 나온값을 인덱스로 사용한다. 그럼 내 키들의 범위가 어떻게 되든간에 내가 원하는 크기의 배열메모리를 설정할 수 있다. direct access table에 비해 어어엄청나게 공간을 효율적으로 사용한다. 추가로, direct access table에서는 인덱스와 키가 동일했기 때문에 value만 저장했지만 이제는 key와 인덱스가 같지 않기 때문에 71번 인덱스에 키인 10007과 value값을 같이 저장해준다. 이제 접근할 때는 key를 해시함수로 돌려서 인덱스를 알아내고 해당 인덱스에 접근해서 가져오면 된다.

*해시함수
-해시함수 복잡한가? 좀 더 찾아볼까... 일단 약간의 설명을 추가한다. 우선 한 해시테이블의 해시함수는 결정론적이어야한다 - 같은 키를 넣을 때 항상 같은 값을 return해야 올바른 인덱스 주소를 알 수 있다. 두번째, 결과 해시값이 고르게 나와야한다. 범위 내에 존재하는 숫자들이 나올 확률이 최대한 비슷해야 한다. 마지막, 빨라야 한다. 저장이든 접근이든 매번 해시함수를 써야한다. 느리면 해시 테이블도 비효율적일 수 밖에 없다. 아 해시 함수를 그렇게 어렵게 받아들이지 않아도 된다. 조건만 만족하면 여러가지 함수를 해시 함수로 쓸 수 있고 몇 개 구현해 봄

파이썬의 hash 함수
-파이썬에는 hash 함수가 내장되어 있는데, 위에서 배운 것과 조금 다르다. 특정 범위내의 자연수가 아니라, 아무 정수를 return한다. 이 함수는 파라미터로 다른 두개의 값을 넣었을 때 절대로! 같은 정수가 나오지 않는다. 즉 바코드처럼 모든 값이 다른 정수를 할당받는다. 그리고 불변 타입 자료형(int, float, str, tuple, boolean)은 전부 hash 함수에 적용가능하다. 그래서 숫자가 아니어도 key에 사용할 수 있는것! (리스트같은 자료형은 안됨) 

해시 테이블 충돌
-배우면서 궁금했던 점이 바로 나왔다. key들을 넣었는데 결과값으로 나오는 자연수 중 겹치는 경우가 있으면 어떡하지? 이렇게 이미 사용하고 있는 인덱스에 새로운 데이터(키, 벨류 쌍)를 저장해야하는 경우가 생겼을 때, 충돌(collision)이 일어났다고 말한다. 해시 테이블에서는 충돌을 잘 처리하는 것이 매우 중요하다. 여러가지 방법이 있는 듯 한데 우선 chaining 이라는 방법을 살펴보자
-chaining: 인덱스 안에 노드를 저장해서 연결리스트를 형성하는 방법이다. node로 키벨류쌍을 저장해주고(self.data 대신 self.key와 self.value) next 메소드를 통해 다음 키벨류로 연결해준다. 음.. 이러면 첫번째 노드만 해당 인덱스주소에 위치하고 나머지 노드들은 이 배열 안이 아닌 메모리 여기저기에 흩어져있는거겠지? 


이제 chaining을 사용하는 해시테이블의 주요 연산들을 알아보자. 일단 순서가 없기 때문에 접근 연산은 없고 크게 탐색, 삽입, 삭제 연산이 있다.

탐색 연산
-원하는 key에 해당하는 value를 찾는 연산. 먼저 키를 해시함수에 넣고 결과값을 통해 배열의 인덱스에 접근한다. 그럼 거기에 연결리스트가 있겠지. 연결리스트를 선형탐색하면서 원하는 key를 탐색한다. 시간복잡도를 생각해보면 해시함수계산O(1) + 배열인덱스접근O(1) + 연결리스트탐색O(m) *해시 테이블의 길이인 n이 아니라 연결리스트의 길이인 m! 
-> 정말 운이 안좋아서 모든 키벨류쌍이 한 인덱스에 저장됐다고 하면 m=n이므로 시간복잡도는 O(n) (왜 분할상환분석을 적용하지않지?)

삽입 연산
- 해시함수를 통해 키를 인덱스로 변환(O(1)) - 인덱스에접근(O(1)) - 인덱스에 있는 연결리스트를 선형탐색하면서 해당 key가 존재하는지 확인(하나의 키에 하나의 벨류만 있어야 함)(O(n)) - 키를 찾으면 .value 값을 변환(O(1)) or 탐색에 실패한다면 연결리스트 마지막에 append 해줌(O(1))
-> 시간복잡도는 O(n)

삭제 연간
- 특정 키에 해당하는 키벨류쌍을 지우는 연산. 해시함수로 인덱스 도출O(1) - 인덱스로 배열에 접근O(1) - 키에 해당하는 노드 탐색O(n) - 노드삭제O(1)
-> 시간복잡도는 O(n)

아! 분할 상환 분석에 관한 설명이 뒤에 나와있었네ㅎ.ㅎ append와 마찬가지로 해당 인덱스의 연결리스트에 모든 키벨류쌍이 들어있는 경우는 거어어어어의 없다. 그래서 일반적인 경우를 생각해보면 키벨류쌍의 개수 n 을 배열의 크기 m으로 나눠서 평균적으로 연결리스트에 n/m개가 들어있을거라고 추측할 수 있다. 그러면 시간복잡도는 O(n/m) 근데 여기서 한가지 가정이 나오는데, 보통 해시테이블의 배열 메모리를 잡을 때 키벨류쌍 개수보다 작게 설정하지는 않는다. 상식적으로 생각해도 그렇잖아? 그래서 일반적으로 m은 n과 유사하거나 그보다 조금 작거나 크다고 보면된다. 그래서 결론은 O(1)이라고 해도 된다는거~
-> 해시테이블의 삽입, 삭제, 탐색 연산은 최악의 경우 O(n)이고 분할 상환 분석, 즉 평균적으로는 O(1)이다. 
 
open addressing
- 해시 테이블의 충돌을 막는 또 다른 방법. 내가 키벨류쌍을 넣고자 하는 인덱스가 이미 차있다면, 연결리스트로 거기에 집어넣는 대신 다른 비어있는 인덱스에 넣는다. 여기서 두가지. 1.어떻게 빈 인덱스를 찾을것인가? 2.언제나 이 key를 통해 해당 인덱스에 접근할 수 있어야하는데 어떻게 해결할 것인가?

-빈 인덱스를 찾기 위해서는 linear probing(선형탐사)을 한다. (가장 기본적인 방법이라고 하는 걸 보니 다른 방식도 있는 듯하다) 선형 탐사는 해당 인덱스 뒤로 한칸한칸 보면서 빈 인덱스가 있는지 확인하는 방식이다. Quadratic probing(제곱 탐사)라는 방식도 있다. 10번에서 충돌이 일어날 때, 1의 제곱 뒤의 칸(11)을 확인 - 2의 제곱 뒤의 칸(15)을 확인 - 3의 제곱 뒤의 칸(24)을 확인 ... 해나가는 방식이다. 근데 이게 리니어랑 사실상 뭐가 다르지? 아- linear하게 open addressing을 해왔다면 특정 인덱스를 기준으로 몰려있을 수 있기 때문에 계속 linear 하게 탐색할 경우 점점 탐색해야 하는 범위가 많아지겠지. 요런 차이가 있다.

-탐색 연산(open addressing 일때)
일단 key를 통해 해시함수 값을 도출하고 그 인덱스부터 차례로 거기에 저장된 데이터와 key가 일치하는지 확인한다. (linear였으면 계속 linear를 쓰고 quadratic이었으면 계속 quadratic을 써야겠지) 사실상 인덱스 한 개 안에서 선형탐색으로 연결리스트를 살펴보는 것과 다를바가 없네. 근데 여기서 유의할 점은 탐색하다가 빈 인덱스를 먼저 만나면 해당 key 값에 어디에도 저장되어있지 않다는 얘기라는거. 나는 open addressing 방식으로 저장한 trace를 그대로 따라가는거니까.
탐색연산은 선형탐사 부분이 시간복잡도를 결정하는데 가장 운이 없을 경우 n번(키벨류쌍개수) 움직여야 하니까 O(n)이다. 삽입도 마찬가지(탐색은 key에 해당하는 인덱스를 찾아야 하고 삽입은 빈 인덱스를 찾아야한다는 차이가 있지만 둘 다 선형 탐사를 진행해야 함)

-삭제 연산
탐색 연산과 마찬가지. 근데 유의할 점은 그 인덱스를 그냥 비워버리면 안된다. 다음에 다른 탐색연산을 돌릴 때 아 여기서 끝인가보다 하고 멈춰버릴 수 있으니까. 그래서 인덱스를 빈 칸으로 두지 않고 대신 deleted 등 사전에 약속된 표시를 남겨준다. 
삭제 연산의 시간 복잡도도 O(n)이다.

-탐색/삽입/삭제 연산이 모두 O(n)이라고 했는데 이건 해시테이블의 크기가 키벨류쌍의 개수와 동일한 조건 속에서 가장 운이 없는 경우이므로 얘도 분할 상환 분석을 해보자. 우선 해시테이블이 얼마나 차있는지 나타내는 변수를 load factor라고 하자. 얘는 해시테이블안에 들어있는 데이터쌍 수(n)를 해시 테이블이 사용하는 배열의 크기(m)로 나눈 값이다. open addressing 방식을 사용할 때는 데이터쌍의 개수가 해시테이블의 크기를 넘을 수 없으므로 load factor는 항상 1보다 작은 값이다. 결과적으로 말하면 탐사 연산의 기대 시간은 1/ (1-load factor) 보다 작다. 로트팩터가 0.5면 기댓값은 2보다 작다. 평균적으로 두 개의 인덱스만 확인해도 찾는다는 얘기. 그래서 탐색 / 삽입 / 삭제 연산은 분할 상환 분석으로 생각할 때 O(1)이라고 할 수 있다. open addressing이든 chaining이든 이 연산들을 평균적으로 O(1)로 할 수 있다는 결론!

* 수학증명(넘어가도 됨)
로드팩터를 알파라고 부르자. 빈 인덱스를 탐사할 때 i번 이상 탐사해야할 확률을 Pi라고 하자. Pi는 n/m * (n-1)/(m-1) * (n-2)/(m-2) * ... * (n-i+2)/(m-i+2) 이고 이는 n/m의 i-1 제곱보다 작다(써보면 이해됨.. 메모장으로 쓰니까 영..) n/m이 알파니까 결국 i번 이상 탐사할 확률은 알파의 아이제곱보다 작다. 평균적으로 몇 번 탐사해야 빈 인덱스를 찾을 수 있을까 하는 기댓값은 P1 + P2 + P3 ... 이다. P와 알파의 관계를 생각하면 기댓값은 1 + 알파 + 알파제곱 + 알파세제곱... 보다 작다는 결론디 나온다. 알파는 0에서 1사이의 수이므로 저 항은 1 / (1 - 알파) 라고 할 수 있다.